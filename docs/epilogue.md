# 后记

![images/010.png](images/010.png "旧时代")

## 写作过程

工作之后，我建立了个人博客，开始与网友们分享一些技术文章，内容多是围绕 LabVIEW 编程语言的。2009 年，我把这部分内容编撰成书出版发行。之后几年我也在继续维护这本书，进行了改版扩充。不过再之后，互联网的管控越来越严格，很多境外网站被屏蔽，也包括我的博客。而我由于没有国内手机号，很多国内的网站也都无法登录留言了。与网友交流越来越少，我也有很长时间失去了写作的动力。

直到 2021 年，从网友那了解到，GitHub 上建站正在成为分享知识的重要途径，尤其难能可贵的是，它居然还没有被国内屏蔽。于是我把那本 LabVIEW 的书搬到了 GitHub 上进行维护（[https://lv.qizhen.xyz/](https://lv.qizhen.xyz/)）。可是，我已经很多年没用 LabVIEW 了，有时候写作起来也感觉力不从心。毕竟，目前工作中主要都在使用 Python，于是我想，也写一写 Python 吧。

这是一本只在网上发布共享的书籍，因此不存在截稿的限期，我将会长时间的去完善和维护它。不过，我还是希望，在真正把它分享给读者之前，首先快速的搭建起一个框架，完成主体内容的草稿。不然什么内容都没有就分享了，可能会很让人失望。我对草稿的要求不是很高：内容不必全面、结构也可以不合理、语言也许不流畅，只要能大致体现全书架构即可。我原本以为需要花费两三个月的时间来准备这样一份草稿，但实际上，只用了一个多月，草稿就大体成型了。这一个月的时间，我每天都要抽出一两个小时的时间专门用来写作，有时周末还要用上一整天的时间。之后恐怕再难以挤出这么多时间了，但我也会尽量保证每周花两个小时来维护和更新书中内容。

虽然，我对草稿的标准定得极低，但考虑到我只能利用业余时间写作，一个月的时间也是非常神速地了。对比我之前写作 LabVIEW 编程语言的书，如果完成同样写作数量，至少需要多花费二到三倍的时间。这与 LabVIEW 这门语言本身不利于写作有关，LabVIEW 与多数编程语言不同，它不是写代码的，而是“画”程序的。这对于编程本身倒也不算是劣势，但是如果想把它整理成文本文档，确实要比那些本就基于文字的编程语言麻烦一些。不过，最为主要的，帮助我加快了写作速度的原因是我这次利用了大语言模型来辅助写作。

## 大语言模型

不得不佩服搞人工智能（AI）那帮专家的造词能力，现在每隔几年就要换个新的流行词来指代人工智能。我最开始学习人工智能的时候，正是它的低谷时期：搞了几十年也没有弄出多少可以实用的产品来，大家甚至都不太喜欢人工智能这个词了，取而代之的是“机器学习”（ML）。后来没过多久，大家就意识到，在众多机器学习算法中，最有潜力的还是多层的人工神经网络。再后来，“多层”不够吸引眼球了，要“深层”才行，于是“深度学习”（DL）红火起来，成了人工智能算法的代表。最近几年，人工神经网络发展速度极快，层次越来越深，从最初的几层，几十层迅速发展到成百上千层。目前已经不再用层来表示模型的规模了，而是用模型参数的数量来表示其规模。现在主流的用于处理自然语言的大模型的参数都有百亿到万亿的规模。作为对比，人脑的神经元的数量大约是在五百亿到一千亿之间。如此巨大的模型，自然不屑与原来的“深度”模型为伍，于是当下最流行的词变成了“大语言模型”（LLM）。

大语言模型领域做的最好的无疑是 OpenAI 公司。由于一直从事人工智能相关的项目，我也特别关注 OpenAI 每个新产品。当它们宣布，在其 GPT 3 大语言模型中添加了程序代码自动生成的功能时，我与几位朋友迫不及待地进行了尝试。具体的测试题目已经记不太清楚了，只记得是在网上随机找到的一个编程面试题目，那个问题有一个代码简单但运行效率差的算法，和一个实现起来极其困难但运行效率高的算法。我们直接将问题描述输入给 GPT 模型，它迅速回应了一个简单直观的解决方案。当我们询问是否能够优化算法以提高运行效率时，它又生成了一段代码冗长但高效的程序。把它的结果放在编译器中一试，完全正确。我们大为震惊，以至于我和我的程序员朋友们都十分担心即将饭碗不保。

在仔细检查 GPT 生成的代码时，我们注意到了其中一个冗长且怪异的变量名，这在一般程序中并不常见。我们好奇地将这个变量名搜索了一番，最终在网络上找到了别人发表的同一题目的一个解决方案，它与 GPT 返回的结果如出一辙。这让我和我的同事们松了一口气 —— GPT 终究还是在“借鉴”已有的资料。当我们测试用它解决那些不太可能在网上找到的问题时，它的表现的确逊色了许多。

然而，我们并没有安心太久，因为 OpenAI 不久后推出了 ChatGPT，其编程能力有了显著提升。至少在解决面试题目方面，我感觉自己再也无法超越这个 AI 模型了。除了 OpenAI 的 ChatGPT，我还使用过 Google 的 Gemini 和 Meta 的 LLAMA 等大语言模型，它们的表现也都非常出色。我本来也想测试几个国内公司的中文模型的，遗憾的是当时它们都对境外用户设了限制，让我无法使用。目前有一些模型解除了限制，我也可以访问了，将来会找时间也对它们做详细测试。

## 大语言模型对我的帮助

科技的发展，让我们这些程序员每天都提心吊胆。“如果战胜不了，就加入他们”。我于是决定探索一下如何利用大型语言模型辅助我的工作。

前一段时间我就发现我所在的公司，已经把大语言模型嵌入了编程开发环境中了。现在编写程序的时候，每起一行，每敲一个字母，编程环境都会给一个出一句写好的候选代码。如果觉得它给的提示有用，敲一下 Tab 键，这段代码就自动写上去了。其实，之前主流的编程环境也都带有一些提示功能，只不过那些提示是基于单词前缀匹配的，比如你敲一个 “a”，它就提示你是不是想要 “add”。这种提示对于我来说不但没有，还非常干扰视线。但现在基于大语言模型的提示则完全不可同日而语，它可以根据上下文来预测你需要的代码。比如当你设置了一个名为 latitude 的变量，它会立刻意识到，下一句你很能要写 longitude；当你打开一个数据表格，它也能猜到下一步你就会去读取它的数据。大语言模型的预测准确率已经非常高了，它给出的候选代码帮我少敲了不少的键盘。

在学习中，我也越来越依赖大语言模型。之前有不懂的问题总是去 Google，但搜索引擎有两个严重的缺陷：一是它并不能真正理解我的问题，而是会把问题拆成关键词，然后按关键词去搜索文章。其次，当它返回一大堆结果后，我可能还是不知道哪个链接与我的问题最相关，有时候需要打开多个链接查看。即便找对了文章，我关注的问题可能也只在这个文章的以个角落，还是要再阅读一些不相关的内容才会发现所需信息。大语言模型可以很好的解决这两个缺陷：我可以直接用自然语言去问大语言模型一个问题，它会理解整个问题，然后直接给出答案，而不是给出候选链接让你自己去分析。

对于一些具体问题，互联网是很难给出现成的答案的。比如，一段程序运行时出错，我们去互联网搜索这个出错信息，也许会找到一些相关的文章，但几乎不可能有文章里出现和我们的问题一模一样的代码。我们还是要参考文章，理解了问题，在应用到自己具体的事例上。有一次，我使用 Pytorch 编写了一小段程序，运行时遇到了一个错误，当时懒得自己调试，就想试试看大语言模型能否应对这样的问题。当我把我的程序，和出错信息一起提交给大语言模型后，它不但指出了我程序中的错误，还一并生成了修改后的代码。新代码果然可以准确无误的的运行。

对我而言，大型语言模型最重要的帮助还不在于编程，而是在于英语写作方面。说句大言不惭的话，我觉得我编程水平还行，要是没有大语言模型，也许我能比多数人优势更大一点。然而，我的英语水平就有些欠缺了，在美国生活了十几年也没什么长进。英语写作尤其困难，常常是一头雾水，写出来的东西我自己也难以判断对错。有时候，我甚至需要求助于正在上小学的儿子来帮我检查。自从有了大型语言模型之后，无论我写什么，我总是先让它帮我进行修改。它不仅能纠正我语言中的错误，还能帮我润色文章，达到我自己无法企及的水平。现在，我正考虑将我之前写的 LabVIEW 教程翻译成英文。之前一直没有下决心开始这个项目，主要就是因为对自己的英语水平不够自信，但现在，我已经充满信心了。

遗憾的是，我曾使用过的几个大型语言模型都是针对英语进行的优化，它们在中文处理方面的能力还不足以帮助我修改中文文章内容。但是，即便他们的中文水平不够完美，做点辅助工作还是绰绰有余的。

在撰写这本 Python 教程的过程中，我也在尽可能充分利用这些大语言模型。所谓万事开头难，拿起笔来，千头万绪，该从哪开始写呢？所以，我问大语言模型的第一个问题是：“我想写一本关于 python 的书，应该包含哪些内容？”它给我的回答是：“写一本关于 Python 的书是一个很好的想法。以下是一些你可能想要包含的主题：1. Python 简介：包括 Python 的历史，它的主要用途，以及为什么它是一个流行的编程语言。2. Python 基础：如变量，数据类型，运算符，控制流（if 语句，for 和 while 循环），函数，错误处理等。3. Python 数据结构：如列表，元组，字典，集合等。......” 我只截取了一小部分，它把常见的 Python 内容都列举出来了。说的头头是道，我打算就按它的建议写了。

在编写细节内容的时候，我同样大量利用了大语言模型，帮我解释概念，帮我生成示例程序等等。

## 大语言模型的问题

大语言模型虽然强大，但也并不是没有缺陷。

首先是它自身的问题：大型语言模型并非全知全能，它的知识来源于互联网。虽然它可以根据曾经学习过的文章，为提示词语生成相关性较高的下文，也能重新组合已有内容，但它并不能真正理解问题的逻辑关系，更无法探索全新领域。对于从未出现过的问题或较为复杂的逻辑，它只能凭空编造答案，而且通常是一本正经的胡说八道。

举个例子，如果你问大语言模型：“老婆被她最好的闺蜜给绿了，我应该如何安慰她？” 如果真人听到这个问题，或者谴责渣男，或者马上意识到这是个玩笑，继续按照搞笑套路给出回答。但 AI 模型是无法理解这个问题的真正含义的，但会根据“绿”，“安慰”等词语，生成一段套路化的回答，比如：“面对这样的情况，首先要理解和支持你的妻子。这里有一些步骤可能会对你有所帮助：1.倾听和理解......” 如果将来这个问题在互联网出现很多次，模型也许可以学到一些更贴切的答案，但目前它也就只能给出机械的回答了。

编写程序也一样，大语言模型擅长解答常见的面试题目，因为类似的资源在网上已经相当丰富。但面对真正独一无二的新任务时，模型常常难以提供满意的答案，它还是会瞎编。它经常会给我写一些看着很像那么回事的程序，然后一运行，结果完全不是想要的。就目前的情况来看，大语言模型是个极为有用的辅助工具，但并非可以完全信赖，它给出的答案，不经验证是不能直接应用于重要场合的。

其次，我也在考虑大语言模型给内容创造者带来的冲击。传统的搜索引擎并不会直接把内容呈现给用户，它只提供链接，用户最终还是在阅读作者的原文。有流量，作者才有动力继续创作。但现在，大语言模型会把多个文章的内容糅合起来，直接呈现给用户。作者再也不知道自己的创作被多少人观看了，有没有帮助。这对于创作者来说是致命打击，尤其是那些依赖流量产生收入的作者。

大语言模型极大地加快了我完成本书的进程。然而，从另一个角度来看，它也降低了写作的门槛，如果过去三个月的劳动现在仅需一个月即可完成，那么这项工作的价值也可能只有以前的三分之一，甚至可能更低。未来，我们可以预见互联网将被 AI 生成的文章、图片、视频所充斥，这将在极大地丰富内容的同时，也将冲淡绝大多数内容的价值。

当然正如上文提到的，大语言模型无法解决新问题，无法创作全新的内容，在这些方面，依然依赖人类专家去解决。在不远的将来，大型语言模型将可能会淘汰一些初级职位，比如初级程序员、初级作家或初级艺术家。然而，今日的专家一度也是从新手成长起来的。如果没有了这些入门级职位，那么未来又将如何培养出更多的高级人才呢？

或许还有另一种可能，AI 的创造能力也将快速提升，水平越来越高，等人类专家都去世了，接班的不是人类新手，而是 AI，再也没有所谓的高级人才了。

## 程序员会被淘汰吗？

短期来看，程序员似乎仍然占据着就业市场的有利地位。毕竟在可预见的未来，AI 模型的训练和部署也是需要程序员来操作的。然而，随着 AI 技术的演进，软件行业将来必然会使用自然语言来替代编程语言。到时候，人们或许只需用口语便能指挥电脑执行各式各样的任务。在那个时代，程序员的角色会被限于维护那些复杂的核心模块，而日常的应用软件开发可能不再依赖于专业程序员的参与了。

我也不知道那一天何时到来，不过我应该不用太担心，那时候我可能已经退休了。

## AI 会有意识吗？

如果结论是人工智能就快有会意识，就要替代人类了，那么这个话题总会吸引很多人。也难怪机器威胁论（当前是智能机器威胁论）每隔十来年就被热炒一番。不过我的观点还是比较保守的，我相信至少在我的有生之年，是不会看到这一天了。尤其是，现在人类自己都不知道意识是个什么东西，又怎么能去判断其它物种有没有意识。现在讨论人工智能与意识，很容易就会脱离技术，去争论“意识”的概念了。

我对于什么是意识没有深刻的理解，但对于 AI 还是比较熟悉的。目前最火的 AI 算法包括大语言模型、扩散模型等都是基于人工神经网络的。它的核心原理是把一个复杂函数表示成许许多多的简单小函数的叠加。我们可以把需要解决的问题抽象成为一个函数。比如，用于聊天的函数，它的输入是一些文字，输出是另一些文字；用于绘图的函数，输入是一些文字，输出是一张图片。这些函数非常复杂，我们无法用一个公式来表达它们，但我们可以使用类似级数分解的方法，把它们拆解成无数简单的小函数。比如，一个大语言模型，就可以看做是上亿个极其简单的 ReLU 函数通过线性叠加构建的一个复杂函数。所以，目前 AI 算法的本质是还是函数拟合，与“意识”似乎扯不上什么关系。

支持 AI 很快就将要“觉醒”的人主要有两个论据，一是 AI 是对人脑的模拟，所以应该可以具有与人类似的意识。的确人脑是神经元构成的，人工神经网络模型也是由“神经元”构成的。但是，我又要重申一下，人工神经网络是对函数的拟合，而非对人脑的模拟。人工神经网络模型与人脑的差别还是很大的。比如最基础的，人脑的神经网络是动态的，神经元之间可以新建连接，也可以断掉已有的连接；但人工神经网路的结构是静态的，训练之前就固定下来了。结构也大为不同：人脑的神经元是真正网状连接的，非线性的；而人工神经网路主要是分层线性连接的。实际上，我们对人脑的了解也还非常有限，还没有完全弄清楚人脑的运行机制。人脑有神经元，并不意味着人的“意识”就只有神经元参与，有些学者就认为量子效应也参与了人的思维活动。人类发现量子效应还不到一百年，也许还有很多人类尚未发现的物理规律也参与了思维活动。这些都是目前人工智能算法完全不具备的，以当前人工智能的简单结构模拟人脑还差的远呢。

另一个论据是认为人工神经网路的参数太多了，如此多的参数，说不定哪天它自己突然灵光一闪，就产生了自我意识呢？这个想法是把 AI 当魔法了。目前的人工智能算法完全基于严格的数学推理和运算，不具备任何魔法能力。让它出现意识，还要依赖人类的主动设计。指望 AI 自己觉醒，就有点类似于，把组成生命的各种化学物质放到一个瓶子里，然后晃一晃瓶子，就以为里面的分子可以自己排列组合，构建一个生命体出来。我们有时候会有一些美好的愿望，希望自己并不了解的东西可以自发的产生魔法和奇迹。但是最终这些愿望基本都会落空。

总之，我对人工智能目前的进步感到振奋，但关于它发展出类似于人类的复杂智力，我想恐怕还需要再多经历几轮技术革命吧。


